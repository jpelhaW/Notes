### Emergent Abilities of Large Language Models
---
- [Zotero Select Link](zotero://select/groups/2480461/items/M7MN6INJ)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/M7MN6INJ)
- Authors: [[Jason Wei]] [[Collin Raffel]] [[Jeff Dean]] [[William Fedus]] 
- Topics: [[nlp_nlu]] [[nlp_lm]]
- Venue: #arXiv
- Year: #2022
---
### Major Contributions
- This paper instead discusses an unpredictable phenomenon that we refer to as emergent abilities of large language models. We consider an ability to be emergent if it is not present in smaller models but is present in larger models.
	- This paper is about the unpredictable phenomena of emergent abilities of large language models.
- 

---
### Secondary Contribution
- the emergence of taskspecific abilities can be analyzed as a function of the language model’s perplexity on a general text corpus such as WikiText103 (Merity et al., 2016)
---
### Limitations/Future Work
---
### Notes (Try to use backlinks)
---
- 1972 essay called “More Is Different” by Nobel prize-winning physicist Philip Anderson (Anderson, 1972): Emergence is when quantitative changes in a system result in qualitative changes in behavior.
- emergent abilities show a clear pattern—performance is nearrandom until a certain critical threshold of scale is reached, after which performance increases to substantially above random.
- Today’s language models have been scaled primarily along three factors: amount of computation, number of model parameters, and training dataset size (Kaplan et al., 2020; Hoffmann et al., 2022).
- The overall implication is that further scaling will likely endow evenlarger language models with new emergent abilities.
	- Tasks that language models cannot currently do are prime candidates for future emergence; for instance, there are dozens of tasks in BIG-Bench for which even the largest LaMDA and GPT-3 models do not achieve above-random performance.
- Although there are dozens of examples of emergent abilities, there are currently few compelling explanations for why such abilities emerge in the way they do