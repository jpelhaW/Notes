### Why AI is harder than we think?
---
- [Zotero Select Link](zotero://select/groups/2480461/items/GX8SDYH9)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/GX8SDYH9)
- Authors: [[Melanie Mitchell]]
- Topics: [[ai_questions]]
- Venue: #arXiv
- Year: #2021
---
### Major Contributions
 - Discuss the open questions spurred about the future and reach of AI, including the age-old challenge of imbuing machines with humanlike common sense
 - Fallacy 1: Narrow intelligence is on a continuum with general intelligence
	 - Everything is a first step towards something - chill out
 - Fallacy 2: Easy things are easy and hard things are hard
	 - Moravec's paradox - Cheker's -> easy; One-year-old-tasks -> hard
 - Fallacy 3: The lure of wishful mnemonics
	 - While machines can outperform humans on these particular benchmarks, AI systems are still far from matching the more general human abilities
 - Fallacy 4: Intelligence is all in the brain
	 - computer scientist Rod Brooks argues, “The reason for why we got stuck in this cul-de-sac for so long was because Moore’s law just kept feeding us, and we kept thinking, ‘Oh, we’re making progress, we’re making progress, we’re making progress.’ But maybe we haven’t been” [65].
---
### Secondary Contribution
- AI is harder than we think, because we are largely unconscious of the complexity of our own thought processes.
---
### Limitations/Future Work
---
### Notes (Try to use backlinks)
- 1980 AI Winter - The problem was that the human experts writing the rules actually rely on subconscious knowledge—what we might call “common sense”—that was not part of the system’s programming
- Deep neural networks are what power all of the major AI advances we’ve seen in the past decade, including speech recognition, machine translation, chat bots, image recognition, game playing, and protein folding, among others
- Deep-learning systems can exhibit brittleness - such systems are susceptible to shortcut learning [27, 28]: learning statistical associations in the training data that allow the machine to produce correct answers but sometimes for the wrong reasons
- Some of the hottest new areas are transformer architectures using self-supervised (or “predictive”) learning [31], meta-learning [32], and deep reinforcement learning [33]
- 
---
