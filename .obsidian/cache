{"files":{"_template.md":{"mtime":1595940315536.8872,"size":366,"hash":"444fee28b46f47e7b4bcd2c33c53db29005ad6a920f0f3a1ecdf4d57326a702a"},"research/2020 - (Re)construing Meaning in NLP.md":{"mtime":1595940315537.8865,"size":5168,"hash":"58dcf4d8dbaa85dddd6570d1157b8614ff7f6adac65c6251243d7af7832f752b"},"research/2020 - Contextual Embeddings When Are TheyWorth It.md":{"mtime":1595940315538.8853,"size":5271,"hash":"bf2249eb28c753493c88d6a814885d8393805864a990333f470d4e9df6fb71e7"},"research/2020 - Dont Stop Pretraining Adapt Language Models to Domains and tasks.md":{"mtime":1595940315539.8867,"size":749,"hash":"7726a279617deb325bd3decc85630835ccd1e85422cec73c1a4f1ca8ec438fc5"},"research/2020- GilBERT Towards pre-trained word-sense disambiguation with bidirection transformers and lexical databases.md":{"mtime":1595940315539.8867,"size":386,"hash":"1c30fc6564e8457c0a06043f7d7c17060e5fd61856670d7b0f06e64a97cefe2d"},"README.md":{"mtime":1595940315535.884,"size":9,"hash":"1f2993541852aff90c5da92621bd5fc15770ac5c3cfcad8fe736afafc66faa2f"}},"metadata":{"48082715cb90becc5e6e95b314093c4fe596ff9982cb7bdf0f9c56535565e4a8":{"links":[{"line":1,"link":"Sean Trott","original":"[[Sean Trott]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" Nathan Schneider"},{"line":1,"link":"Nathan Schneider","original":"[[Nathan Schneider]]","displayText":"","beforeContext":"Auhtor: Sean Trott ","afterContext":""},{"line":2,"link":"nlp_theory","original":"[[nlp_theory]]","displayText":"","beforeContext":"Tags: ","afterContext":" semantics NLP"},{"line":2,"link":"semantics","original":"[[semantics]]","displayText":"","beforeContext":"Tags: nlp_theory ","afterContext":" NLP"},{"line":2,"link":"NLP","original":"[[NLP]]","displayText":"","beforeContext":"Tags: nlp_theory semantics ","afterContext":""},{"line":8,"link":"theory","original":"[[theory]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":3,"tag":"#ACL"},{"line":23,"tag":"#perspective"},{"line":23,"tag":"#prominence"},{"line":23,"tag":"#resolution"},{"line":23,"tag":"#configuration"},{"line":23,"tag":"#metaphor"}],"headings":[{"line":7,"heading":"Techniques","level":3},{"line":11,"heading":"Goal","level":3},{"line":15,"heading":"Major Contributions","level":3},{"line":19,"heading":"Secondary Contributions","level":3},{"line":22,"heading":"Limitations/Future Work","level":3},{"line":26,"heading":"Notes","level":3}]},"3df95b7fa77eef6ba9af1e0a26dcb9666e83ce273b2854d79d077685a552315f":{"links":[{"line":1,"link":"Simran Arora","original":"[[Simran Arora]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" Christopjer Ré"},{"line":1,"link":"Christopjer Ré","original":"[[Christopjer Ré]]","displayText":"","beforeContext":"Auhtor: Simran Arora ","afterContext":""},{"line":2,"link":"nlp_embeddings","original":"[[nlp_embeddings]]","displayText":"","beforeContext":"Tags: ","afterContext":" nlp_transformers"},{"line":2,"link":"nlp_transformers","original":"[[nlp_transformers]]","displayText":"","beforeContext":"Tags: nlp_embeddings ","afterContext":""},{"line":8,"link":"BERT","original":"[[BERT]]","displayText":"","beforeContext":"","afterContext":""},{"line":9,"link":"GloVe","original":"[[GloVe]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":3,"tag":"#ACL"}],"headings":[{"line":7,"heading":"Techniques","level":3},{"line":12,"heading":"Goal","level":3},{"line":16,"heading":"Major Contributions","level":3},{"line":19,"heading":"Secondary Contributions","level":3},{"line":22,"heading":"Limitations/Future Work","level":3},{"line":25,"heading":"Notes","level":3}]},"8fc520817b0585ad3506b4344926e5ccea489df78c5246dc23ec85d51a15d45c":{"links":[{"line":4,"link":"first author","original":"[[first author]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" last auhtor relevant other"},{"line":4,"link":"last auhtor","original":"[[last auhtor]]","displayText":"","beforeContext":"Auhtor: first author ","afterContext":" relevant other"},{"line":4,"link":"relevant other","original":"[[relevant other]]","displayText":"","beforeContext":"Auhtor: first author last auhtor ","afterContext":""},{"line":5,"link":"topic1","original":"[[topic1]]","displayText":"","beforeContext":"Topics: ","afterContext":" #topic2"},{"line":5,"link":"#topic2","original":"[[#topic2]]","displayText":"","beforeContext":"Topics: topic1 ","afterContext":""}],"embeds":[],"tags":[{"line":6,"tag":"#venue"},{"line":7,"tag":"#year"}],"headings":[{"line":9,"heading":"Techniques","level":3},{"line":13,"heading":"Goal","level":3},{"line":15,"heading":"Major Contributions","level":3},{"line":17,"heading":"Secondary Contribution","level":3},{"line":19,"heading":"Limitations/Future Work","level":3},{"line":21,"heading":"Notes (Try to use backlinks)","level":3}]},"7644a8f46512197571f30ae99301a36cab38da81d07d15841f962474b030d8fe":{"links":[{"line":4,"link":"first author","original":"[[first author]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" last auhtor relevant other"},{"line":4,"link":"last auhtor","original":"[[last auhtor]]","displayText":"","beforeContext":"Auhtor: first author ","afterContext":" relevant other"},{"line":4,"link":"relevant other","original":"[[relevant other]]","displayText":"","beforeContext":"Auhtor: first author last auhtor ","afterContext":""},{"line":5,"link":"topic1","original":"[[topic1]]","displayText":"","beforeContext":"Topics: ","afterContext":" #topic2"},{"line":5,"link":"#topic2","original":"[[#topic2]]","displayText":"","beforeContext":"Topics: topic1 ","afterContext":""}],"embeds":[],"tags":[{"line":6,"tag":"#venue"},{"line":7,"tag":"#year"}],"headings":[{"line":9,"heading":"Techniques","level":3},{"line":11,"heading":"Goal","level":3},{"line":14,"heading":"Major Contributions","level":3},{"line":16,"heading":"Secondary Contribution","level":3},{"line":18,"heading":"Limitations/Future Work","level":3},{"line":20,"heading":"Notes (Try to use backlinks)","level":3}]},"9817337c3fc4b0b112c6207e6a982cc98a44512c0f4f51fd26dbcbc54e2c8904":{"links":[{"line":1,"link":"Suchin Gururangan","original":"[[Suchin Gururangan]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" Noah Smith Iz Beltagy"},{"line":1,"link":"Noah Smith","original":"[[Noah Smith]]","displayText":"","beforeContext":"Auhtor: Suchin Gururangan ","afterContext":" Iz Beltagy"},{"line":1,"link":"Iz Beltagy","original":"[[Iz Beltagy]]","displayText":"","beforeContext":"Auhtor: Suchin Gururangan Noah Smith ","afterContext":""},{"line":2,"link":"nlp_lm","original":"[[nlp_lm]]","displayText":"","beforeContext":"Topics: ","afterContext":" nlp_task nlp_lm"},{"line":2,"link":"nlp_task","original":"[[nlp_task]]","displayText":"","beforeContext":"Topics: nlp_lm ","afterContext":" nlp_lm"},{"line":2,"link":"nlp_lm","original":"[[nlp_lm]]","displayText":"","beforeContext":"Topics: nlp_lm nlp_task ","afterContext":""},{"line":9,"link":"Pretraining","original":"[[Pretraining]]","displayText":"","beforeContext":"They show a second ","afterContext":" in domain domain-adaptative pretraining (DAPT) leads to performance gains, under both high and low resource settings."},{"line":14,"link":"TAPT","original":"[[TAPT]]","displayText":"","beforeContext":"Highlight of how task-adaptative pretraining ","afterContext":" and DAPT"},{"line":14,"link":"DAPT","original":"[[DAPT]]","displayText":"","beforeContext":"Highlight of how task-adaptative pretraining TAPT and ","afterContext":""},{"line":17,"link":"TAPT","original":"[[TAPT]]","displayText":"","beforeContext":"","afterContext":" is even better when unlabeled data from the task distribution"}],"embeds":[],"tags":[{"line":3,"tag":"#ACL"}],"headings":[{"line":6,"heading":"Techniques","level":3},{"line":8,"heading":"Goal","level":3},{"line":12,"heading":"Major Contributions","level":3},{"line":16,"heading":"Secondary Contribution","level":3},{"line":19,"heading":"Limitations/Future Work","level":3},{"line":21,"heading":"Notes (Try to use backlinks)","level":3}]},"444fee28b46f47e7b4bcd2c33c53db29005ad6a920f0f3a1ecdf4d57326a702a":{"links":[{"line":4,"link":"first author","original":"[[first author]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" last auhtor relevant other"},{"line":4,"link":"last auhtor","original":"[[last auhtor]]","displayText":"","beforeContext":"Auhtor: first author ","afterContext":" relevant other"},{"line":4,"link":"relevant other","original":"[[relevant other]]","displayText":"","beforeContext":"Auhtor: first author last auhtor ","afterContext":""},{"line":5,"link":"topic1","original":"[[topic1]]","displayText":"","beforeContext":"Topics: ","afterContext":" #topic2"},{"line":5,"link":"#topic2","original":"[[#topic2]]","displayText":"","beforeContext":"Topics: topic1 ","afterContext":""}],"embeds":[],"tags":[{"line":6,"tag":"#venue"},{"line":7,"tag":"#year"}],"headings":[{"line":9,"heading":"Techniques","level":3},{"line":13,"heading":"Goal","level":3},{"line":15,"heading":"Major Contributions","level":3},{"line":17,"heading":"Secondary Contribution","level":3},{"line":19,"heading":"Limitations/Future Work","level":3},{"line":21,"heading":"Notes (Try to use backlinks)","level":3}]},"58dcf4d8dbaa85dddd6570d1157b8614ff7f6adac65c6251243d7af7832f752b":{"links":[{"line":1,"link":"Sean Trott","original":"[[Sean Trott]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" Nathan Schneider"},{"line":1,"link":"Nathan Schneider","original":"[[Nathan Schneider]]","displayText":"","beforeContext":"Auhtor: Sean Trott ","afterContext":""},{"line":2,"link":"nlp_theory","original":"[[nlp_theory]]","displayText":"","beforeContext":"Tags: ","afterContext":" semantics NLP"},{"line":2,"link":"semantics","original":"[[semantics]]","displayText":"","beforeContext":"Tags: nlp_theory ","afterContext":" NLP"},{"line":2,"link":"NLP","original":"[[NLP]]","displayText":"","beforeContext":"Tags: nlp_theory semantics ","afterContext":""},{"line":8,"link":"theory","original":"[[theory]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":3,"tag":"#ACL"},{"line":23,"tag":"#perspective"},{"line":23,"tag":"#prominence"},{"line":23,"tag":"#resolution"},{"line":23,"tag":"#configuration"},{"line":23,"tag":"#metaphor"}],"headings":[{"line":7,"heading":"Techniques","level":3},{"line":11,"heading":"Goal","level":3},{"line":15,"heading":"Major Contributions","level":3},{"line":19,"heading":"Secondary Contributions","level":3},{"line":22,"heading":"Limitations/Future Work","level":3},{"line":26,"heading":"Notes","level":3}]},"bf2249eb28c753493c88d6a814885d8393805864a990333f470d4e9df6fb71e7":{"links":[{"line":1,"link":"Simran Arora","original":"[[Simran Arora]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" Christopjer Ré"},{"line":1,"link":"Christopjer Ré","original":"[[Christopjer Ré]]","displayText":"","beforeContext":"Auhtor: Simran Arora ","afterContext":""},{"line":2,"link":"nlp_embeddings","original":"[[nlp_embeddings]]","displayText":"","beforeContext":"Tags: ","afterContext":" nlp_transformers"},{"line":2,"link":"nlp_transformers","original":"[[nlp_transformers]]","displayText":"","beforeContext":"Tags: nlp_embeddings ","afterContext":""},{"line":8,"link":"BERT","original":"[[BERT]]","displayText":"","beforeContext":"","afterContext":""},{"line":9,"link":"GloVe","original":"[[GloVe]]","displayText":"","beforeContext":"","afterContext":""}],"embeds":[],"tags":[{"line":3,"tag":"#ACL"}],"headings":[{"line":7,"heading":"Techniques","level":3},{"line":12,"heading":"Goal","level":3},{"line":16,"heading":"Major Contributions","level":3},{"line":19,"heading":"Secondary Contributions","level":3},{"line":22,"heading":"Limitations/Future Work","level":3},{"line":25,"heading":"Notes","level":3}]},"7726a279617deb325bd3decc85630835ccd1e85422cec73c1a4f1ca8ec438fc5":{"links":[{"line":1,"link":"Suchin Gururangan","original":"[[Suchin Gururangan]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" Noah Smith Iz Beltagy"},{"line":1,"link":"Noah Smith","original":"[[Noah Smith]]","displayText":"","beforeContext":"Auhtor: Suchin Gururangan ","afterContext":" Iz Beltagy"},{"line":1,"link":"Iz Beltagy","original":"[[Iz Beltagy]]","displayText":"","beforeContext":"Auhtor: Suchin Gururangan Noah Smith ","afterContext":""},{"line":2,"link":"nlp_lm","original":"[[nlp_lm]]","displayText":"","beforeContext":"Topics: ","afterContext":" nlp_task nlp_lm"},{"line":2,"link":"nlp_task","original":"[[nlp_task]]","displayText":"","beforeContext":"Topics: nlp_lm ","afterContext":" nlp_lm"},{"line":2,"link":"nlp_lm","original":"[[nlp_lm]]","displayText":"","beforeContext":"Topics: nlp_lm nlp_task ","afterContext":""},{"line":9,"link":"Pretraining","original":"[[Pretraining]]","displayText":"","beforeContext":"They show a second ","afterContext":" in domain domain-adaptative pretraining (DAPT) leads to performance gains, under both high and low resource settings."},{"line":14,"link":"TAPT","original":"[[TAPT]]","displayText":"","beforeContext":"Highlight of how task-adaptative pretraining ","afterContext":" and DAPT"},{"line":14,"link":"DAPT","original":"[[DAPT]]","displayText":"","beforeContext":"Highlight of how task-adaptative pretraining TAPT and ","afterContext":""},{"line":17,"link":"TAPT","original":"[[TAPT]]","displayText":"","beforeContext":"","afterContext":" is even better when unlabeled data from the task distribution"}],"embeds":[],"tags":[{"line":3,"tag":"#ACL"}],"headings":[{"line":6,"heading":"Techniques","level":3},{"line":8,"heading":"Goal","level":3},{"line":12,"heading":"Major Contributions","level":3},{"line":16,"heading":"Secondary Contribution","level":3},{"line":19,"heading":"Limitations/Future Work","level":3},{"line":21,"heading":"Notes (Try to use backlinks)","level":3}]},"1c30fc6564e8457c0a06043f7d7c17060e5fd61856670d7b0f06e64a97cefe2d":{"links":[{"line":4,"link":"first author","original":"[[first author]]","displayText":"","beforeContext":"Auhtor: ","afterContext":" last auhtor relevant other"},{"line":4,"link":"last auhtor","original":"[[last auhtor]]","displayText":"","beforeContext":"Auhtor: first author ","afterContext":" relevant other"},{"line":4,"link":"relevant other","original":"[[relevant other]]","displayText":"","beforeContext":"Auhtor: first author last auhtor ","afterContext":""},{"line":5,"link":"topic1","original":"[[topic1]]","displayText":"","beforeContext":"Topics: ","afterContext":" #topic2"},{"line":5,"link":"#topic2","original":"[[#topic2]]","displayText":"","beforeContext":"Topics: topic1 ","afterContext":""}],"embeds":[],"tags":[{"line":6,"tag":"#venue"},{"line":7,"tag":"#year"}],"headings":[{"line":9,"heading":"Techniques","level":3},{"line":11,"heading":"Goal","level":3},{"line":14,"heading":"Major Contributions","level":3},{"line":16,"heading":"Secondary Contribution","level":3},{"line":18,"heading":"Limitations/Future Work","level":3},{"line":20,"heading":"Notes (Try to use backlinks)","level":3}]},"1f2993541852aff90c5da92621bd5fc15770ac5c3cfcad8fe736afafc66faa2f":{"links":[],"embeds":[],"tags":[],"headings":[{"line":0,"heading":"Notes","level":1}]}},"algorithmVersion":9}