### Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data
---
- [Zotero Select Link](zotero://select/groups/2480461/items/ZRGCCW2M)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/ZRGCCW2M)
- Authors: [[Emily Bender]]  [[Alexander Koller]]
- Topics: [[nlp]] [[nlp_nlu]] [[nlp_explain]]
- Venue: #ACL 
- Year: #2020
---
### Major Contributions
- Opiniated discussion on how major hyped projects in [[NLP]] claim to have a grasp on meaning, when it's not the case
- A model trained purely on form will not have sufficient signal to learn the relation between form and the non-linguistic intent of human language users **nor** between form and the standing meaning the linguistics system assigns to each form.
- 
---
### Secondary Contribution
---
### Limitations/Future Work
- Not sure if I agree with this paper, but they present a valuable discussion about how [[NLP]] and its evaluation can put us in a "comfort zone"
- 
---
### Notes (Try to use backlinks)
- They advocate a system trained only on form has a priori no way to learn meaning
- The [[LM]] task, because it only uses form as a training data, cannot in principle lead to learning of model
- Definition of form: observable realization of language
- Definition of [[meaning]] - relation between the form and something external to language
	- natural language expression + communicative items = understand
- Sections 8 and 9 are particularly interessant: How do we know that incremental progress on today's tasks will take us to our end goal?
- Not sure if they were the first to create the term (probably not) [[BERTLogogy]]
- 
---
