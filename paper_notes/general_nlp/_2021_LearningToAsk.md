### Learning How to Ask: Querying LMs with Mixtures of Soft Prompts
---
- [Zotero Select Link](zotero://select/groups/2480461/items/XNZP3P6A)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/XNZP3P6A)
- Authors: [[Guanghui Qin]] [[Jason Eisner]]
- Topics: [nlp_QA]] [[nlp_lm]]
- Venue: #NAACL
- Year: #2021
---
### Major Contributions
- We explore the idea of learning prompts by gradient descent—either fine-tuning prompts taken from previous work, or starting from random initialization
---
### Secondary Contribution
---
### Limitations/Future Work
---
### Notes (Try to use backlinks)
- We observe that when we are querying an LM rather than a human, we have the opportunity to tune prompts using gradient descent
- language models know more than we realized. We just had to find the right ways to ask
- Here and in the supplementary material, we report its average performance on all test examples, with precision-at-1 (P@1), precision-at-10 (P@10) and mean reciprocal rank (MRR) as metrics.
- we have demonstrated startlingly large and consistent improvements from rapidly learning prompts that work—even though the resulting “soft prompts” are no longer natural language.
---
