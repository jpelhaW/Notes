### Improving Factuality and Reasoning in Language Models through Multiagent Debate
---
- [Zotero Select Link](zotero://select/groups/2480461/items/6LY5ZS4L)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/6LY5ZS4L)
- Authors: [[Yilun Du]]  [[Joshua Tenenbaum]] 
- Topics: [[nlp_agent]] [[nlp_llm]] [[nlp_debate]]
- Venue: #arxiv #google_brain #MIT
- Year: #2023

---
### Major Contributions
- “we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer.” (Du et al., 2023, p. 1)
	- “Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to” (Du et al., 2023, p. 1)
- Questions: “(1) To what extent does multiagent debate improve reasoning? (2) To what extent does multiagent debate improve factual validity? (3) What design choices enable multiagent debate to improve language generation performance?” (Du et al., 2023, p. 4)
- 
- [Link](https://composable-models.github.io/llm_debate/)
---
### Secondary Contribution
- “To help evaluate the effect of our approach on factual accuracy, we introduce a new benchmark and dataset evaluating factual accuracy of famous computer scientist biographies.” (Du et al., 2023, p. 2)
- Tasks as really focused on math
---
### Limitations/Future Work
- we evaluate our approach across benchmarks mainly using three agents with two rounds of debates, - limited number of rounds and agents. no differentiation between agents it seems
---
### Notes (Try to use backlinks)
- we propose a complementary approach inspired by [[The Society of Mind]] [19] and [[multi-agent]] settings, where multiple language model instances (or agents) individually propose and jointly debate their responses and reasoning processes to arrive at a single common answer.
	- “given a query, multiple instances of a language model first generate individual candidate answers to a query. Then each individual model instance reads and critiques the responses of all other models and uses this content to update its own answer.” (Du et al., 2023, p. 1)
- “debate approach outperforms single model baselines such as zero-shot chain of thought [11] and reflection [26, 18] on a variety of six reasoning, factuality, and question-answering tasks.” (Du et al., 2023, p. 2)
- “Given an initial query, we find that individual model instances propose a diverse range of answers despite being the same model class (although we also investigate the case of mixing different model types, such as [[chatGPT]] [21] and Bard [23]).” (Du et al., 2023, p. 2)
- “Debate results are also less likely to include false facts that models are internally uncertain of. This is because as the debate progresses, individual model instances tend to disagree on uncertain facts and omit them from the answer” (Du et al., 2023, p. 2)
- “we find that debate does not just act to amplify one correct answer in a model quorum - we find many cases where all the models initially make incorrect predictions, but then arrive at the correct answer as debate progresses” (Du et al., 2023, p. 2)
- “Given multiple rounds of debate, how can we ensure that a set of language model agents will converge to a final consensus answer? In general, debate can be seen as a multi-agent game, where convergence is not guaranteed. Empirically, however, we find that language models are able to converge on a single shared answer after multiple rounds of debate” (Du et al., 2023, p. 4)
	- “We found that we could control the duration of debates by how changing how much a language model trusts its own outputs over those generated by other models through different prompts.” (Du et al., 2023, p. 4)
- “Due to computational expense, we evaluate our approach across benchmarks mainly using three agents with two rounds of debates, although we found further gains with both more agents and rounds of debate (Figure 10). Additional evaluation details are found in the Appendix” (Du et al., 2023, p. 5)
- “Qualitative Results. In Figure 4, 5, we provide qualitative illustrations of the debate procedure between models. Interestingly, we find cases in which all models initially give an incorrect response, yet the result of debate still obtains the correct answer as agents critique each others’ reasoning. Thus, the purpose of our debate isn’t just to amplify a correct answer – all models can initially be wrong but arrive at the correct answer through the debate process” (Du et al., 2023, p. 6)
- “We analyze the performance of each method in Table 2. We found that approaches based on reflection led to poor performance in the factuality setting. In contrast, debate gives the best performance in this setting also, and significantly outperforms each baseline. We illustrate a debate between agents on the biography task in Figure 7 and on MMLU in Figure 8. We found that multiagent debate improved and settled on bullets that were more consistent across agents.” (Du et al., 2023, p. 7)
- ![[2023_Multiagent_Debate_results.png]]
- ![[2023_Multiagent_Debate_debate_round.png]]
- ![[2023_Multiagent_Debate_agent_detail_round.png]]
- “In Figure 10(b), we increase the debate length between agents, while fixing the number of agents to three. We find that on the arithmetic task, the performance also monotonically increases with debate length. However, we found that additional debate rounds above four led to a similar final performance to 4 rounds of debate.” (Du et al., 2023, p. 7)
- “We find that debates using longer prompts lead to slower convergence to correct answers, but also lead to a better final consensus on the correct answer. We provide an analysis of consensus between agents in Figure 14.” (Du et al., 2023, p. 8)
- “Summarization. While in the majority of experiments in the paper we directly concatenate the responses of other agents as context for an agent to generate a new response, this is expensive when the number of agents involved in debate gets large. We may alternatively first summarize the responses from all other agents into a single response that we provide to agent at each round for more efficient debate.” (Du et al., 2023, p. 8)
- “we ask chatGPT and Bard [23] language models to debate with each other on a set of 20 GSM8K math problems. In this set, we find that multi-agent debate improves the performance of both agents, with Bard solving 11 problems, chatGPT solving 14 problems, and joint multi-agent debate solving 17 problems.” (Du et al., 2023, p. 9)
- Related Work
	- “Our work provides an alternative way to obtain reasoning and factuality in language models using multiagent debates, which only requires black-box access to a language generator. Prior work also has explored how to take the majority vote across different models [15, 3, 29, 28] while in this work, we use the power of a language model to combine different answers.” (Du et al., 2023, p. 9)
	- “Most similar to our work, [14, 32] propose to combine multiple different large pretrained models together for multimodal reasoning. In contrast, in our work, we aim to use communication between different language models to enable more effective reasoning and factuality in language models.” (Du et al., 2023, p. 9)
---
