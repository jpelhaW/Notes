### CoMM: Collaborative Multi-Agent, Multi-Reasoning-Path Prompting for Complex Problem Solving
---
- [Zotero Select Link](zotero://select/groups/5566776/items/9LSS5ZWT)
- [Zotero URI](https://www.zotero.org/groups/5566776/items/9LSS5ZWT)
- Authors: [[Pei Chen]]  [[Shuai Zhang]] 
- Topics: [[agents_reasoning]] [[nlp_agents]] [[agents_learning]] [[agents_task_solving]]
- Venue: #arxiv #NAACL #Amazon #AWS
- Year: #2024

---
### Major Contributions
- [GitHub](https://github.com/ amazon-science/comm-prompt.)
- “We propose a collaborative multi-agent framework (CoMM) that prompts LLMs to play different roles with different domain knowledge or task-solving duties for problemsolving. In particular, we propose a multi-path reasoning method that enables few-shot learning in the multi-agent framework. Empirical results on multiple complicated college-level science problems show that our method significantly outperforms strong baselines. Our further analysis shows that it is beneficial to include multiple agents for the collaboration, instead of prompting one agent to play multiple roles altogether.” (Chen et al., 2024, p. 2)
---
### Secondary Contribution
- 
---
### Limitations/Future Work
- Loose definition of a complicated problem
- “The empirical results obtained from two college-level science tasks not only validate the efficacy of our method but also highlight the potential of few-shot prompting in multi-agent contexts.” (Chen et al., 2024, p. 7) 
---
### Notes (Try to use backlinks)
- we aim to push the upper bound of the reasoning capability of LLMs by proposing a collaborative multi-agent, multi-reasoning-path ([[collaborative multi-agent, multi-reasoning-path|CoMM]]) prompting framework. Specifically, we prompt LLMs to play different roles in a problem-solving team, and encourage different role-play agents to collaboratively solve the target task.
	- “we discover that applying different reasoning paths for different roles is an effective strategy to implement few-shot prompting approaches in the multiagent scenarios.” (Chen et al., 2024, p. 1)
- “Multi-agent Prompting For multi-agent prompting, we will have n language models P1(θ1), P2(θ2), ... , Pn(θn) that play different agents or roles in the framework. These language models can be the same (θ1 = θ2... = θn) or different (θ1! = θ2...! = θn).” (Chen et al., 2024, p. 3)
- “Collaborative Zero-shot Scenario In our collaborative multi-agent setting, we restrict the multiple agents to inherit from the same language models and the count of agents to be three. Then we have three language models P1(θ), P2(θ), P3(θ) as the agents: P1(θ) and P2(θ) as the problem-solving experts and P3(θ) as the summarizar, as shown in Figure 2.” (Chen et al., 2024, p. 4)
- “**Which agent should we give the few-shot examples?** We adopt a multi-path reasoning approach that gives the fewshot examples to the different agents. In particular, different agents will have their own expertisebased reasoning path in the few-shot demonstrations.” (Chen et al., 2024, p. 4)
- “Moral Scenarios is aother dataset from MMLU (Hendrycks et al., 2020). Moral Scenarios focus on advanced professional-level social science problems that are yet challenging for large language models, which is among the worst performing tasks for many language models (Ma et al., 2023).” (Chen et al., 2024, p. 4)
	- “Both datasets are multiple choice questions, and we use the correct rate (Accuracy) as the metric for comparison.” (Chen et al., 2024, p. 4)
- **“Settings for Moreal Scenarios** In the zero-shot setting, we prompt the first agent P1(θ) to be a task decomposer, the second agent P2(θ) to be a subproblem solver, and the third agent P3(θ) to be the summarize. In the few-shot setting, we also give each expert 5 examples, and we prompt the first agent P1(θ) to be a chain-of-thought reasoner with CoT reasoning path, the second agent P2(θ) to be a Thought reasoner with thought experiment path, and the third agent P3(θ) to be the summarize” (Chen et al., 2024, p. 5)
- “It is saliently observable that the proposed CoMM approach can outperform the state-of-theart baselines on both zero-shot and few-shot settings” (Chen et al., 2024, p. 5)
- “**Are Multiple Independent Agents Necessary**?” (Chen et al., 2024, p. 6)
	- the performance of multiple agents (CoMM) significantly outperforms the single-agent approach, across all benchmarks and settings. We hypothesize the possible reason is that a single instance of LLMs tends to be self-consistent, and prompting it to switch among different roles confuses the model to make the right predictions. -> weak answer : it basically says : yes because we have better results
- **Are Multiple Domain Experts Necessary?** (Chen et al., 2024, p. 6)
	- “Here we empirically demonstrate whether the multiple domain experts are collaborating. As shown in Table 3, the single-expert approach shows poor performance, and could not beat the CoT benchmark.” (Chen et al., 2024, p. 6) - same problem as before
- “**Are Multiple Turns Discussions Necessary**?” (Chen et al., 2024, p. 6)
	- 
---
