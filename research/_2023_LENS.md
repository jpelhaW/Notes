### LENS : A Learnable Evaluation Metric for Text Simplification
---
- [Zotero Select Link](zotero://select/groups/2480461/items/JSIBXSN8)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/JSIBXSN8)
- Authors: [[Mounica Maddela]] [[Wei Dao]]
- Topics: [[nlp_metrics]] [[nlp_text_summarization]]
- Venue: #arxiv #ACL
- Year: #2023

---
### Major Contributions
- we present [[LENS]], a Learnable Evaluation Metric for Text Simplification.
- [Website](http://lens-score.com/)
---
### Secondary Contribution
- Empirical experiments show that LENS achieves a higher correlation of 0.331 with human ratings on SIMPEVAL2022, which is more than twice as high as the correlation scores of 0.112 and 0.149 by BERTScore and SARI, respectively. 
- We further demonstrate that incorporating LENS into decoding process, using minimum Bayes risk framework (Fernandes et al., 2022), can directly improve the automatic text simplification system’s performance
---
### Limitations/Future Work
- 
---
### Notes (Try to use backlinks)
- An ideal automatic metric should accommodate these diverse choices while capturing semantic similarity and fluency.
- [[SARI]] (Xu et al., 2016) is the most commonly used metric for text simplification that computes F1/precision scores of the n-grams inserted, deleted, and kept when compared to human references.
- An ideal automatic metric for text simplification should capture both semantic similarity and the edits performed by the system.
- To tackle the challenge of limited human evaluation data, we curate [[SIMPEVAL]], a corpus containing over 13K human judgements on 2.8K simplification from 26 systems. This facilitates the training and evaluation of [[LENS]] (A Learnable Evaluation Metric for Text Simplification), the first supervised automatic metric for text simplification evaluation.
- “For training, besides considering all references equally (i.e., LENSall when k = n in Eq. (1)), we also adopt a reference-adaptive loss that selects a subset of references closer to s in terms of edit operations rather than the entire set R. It encourages the metric to consider that different simplifications (e.g., paraphrasing-focused, deletion-focused, with or without splitting) can be acceptable, as long as they are close to some (not necessarily all) of the human references” (Maddela et al., 2023, p. 16386)
- 
- - ![[2023_LENS_examples.png]]
---
