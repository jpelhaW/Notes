### What Do NLP Researchers Believe? Results of the NLP Community Metasurvey
---
- [Zotero Select Link](zotero://select/groups/2480461/items/PZ5BFSSS)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/PZ5BFSSS)
- Authors: [[Julian Michael]]  [[Samuel R. Bowman]] 
- Topics: [[nlp_general]] [[nlp_survey]]
- Venue: #arxiv #ACL
- Year: #2023

---
### Major Contributions
- NLP Community Metasurvey. May-Jun 2022
- [Link for the survey](https://nlpsurvey.net/)
- 
---
### Secondary Contribution
- we find that the community greatly overestimates its own belief in the usefulness of benchmarks and the potential for scaling to solve real-world problems
---
### Limitations/Future Work
- “Our results are descriptive, not prescriptive, as these issues cannot be resolved by majority vote” (Michael et al., 2023, p. 16334)
- For gender, we use the publicly available statistics from attendance at ACL 2017 in Vancouver (which lacked a specific “non-binary” category). - why not a more recent one?
---
### Notes (Try to use backlinks)
- Currently, the field focuses too much on scaling up machine learning models
- We don’t include a neutral middle option because our intent is to push respondents to consider which side they stand on; we instruct them to choose WEAKLY AGREE or WEAKLY DISAGREE if they have even slight preferences for one side or the other (e.g., “depends, leaning negative”).
- 480 people completed the survey, of which 327 (68%) are in our target demographic, reporting that they co-authored at least 2 ACL publications between 2019 and 2022.
	- Based on the ACL Anthology, 6323 people met this requirement during the survey period, so we have responses from about 5% of the total.
- **Belief in scaling maximalism is rare and greatly overestimated, but concerns about AGI are not uncommon.** Only a small minority (17%) of respondents agree with the hypothesis that scaling up current systems and methods could solve “practically any important problem” in NLP (Figure 3b, Q2-1), but this view is perceived as much more popular (at 47% predicted agreement).
- It is worth considering how views on these issues may have changed since the survey was run in mid2022: Bubeck et al. (2023) argue that GPT-4 (OpenAI, 2023) is a step towards artificial general intelligence, and scaling training data has brought more performance gains (Anil et al., 2023), but state-ofthe-art models also leverage new techniques such as Constitutional AI (Bai et al., 2022).
- **Belief in the value of interdisciplinary insights is greatly underestimated, with predicted trend reversals in favor of theoretically-informed approaches to NLP.**  NLP researchers should place higher priority on incorporating insights from relevant domain sciences such as sociolinguistics, cognitive science, and human–computer interaction (82%, Figure 4a, Q5-7), while greatly underestimating the number of other NLP researchers that share this belief (53% predicted).
- **AGI and LMs understanding language are known controversies.** We find that the community is nearly evenly split on two controversial issues: whether we should be concerned with AGI (58%, Figure 3c, Q3-1), and whether language models understand language (51%, Figure 3d, Q4-1; Bender and Koller, 2020; Michael, 2020; Potts, 2020; Merrill et al., 2021; Bommasani et al., 2021).
- **The net impact of NLP is believed to be good, but with high stakes.** 
- that there is a fairly common but underappreciated belief in the NLP community that researchers should be working on new ways of formulating the problems we’re trying to solve, and that such work could have high impact.
- **Concerns about private influence track concerns about scale. T**hese correlations suggest that NLP researchers who see the influence of industry as problematic may hold this view in part because of concerns with the large-scale, compute-intensive research paradigm that is spearheaded largely by private firms.
- **Believing that LMs understand language is predictive of belief in AGI and the promise of scale.**
- Among our respondents, women are more likely to believe in the importance of linguistic theory and inductive bias, believe that language models don’t understand language, and believe that the carbon footprint of training large models should be a concern for NLP researchers. Whereas, men are more likely to believe that the future impact of NLP research will be good, and under-represented minorities are more likely to agree that AI could have catastrophic consequences.
- the idea that mere scale will solve most of NLP is much less controversial (and much less believed) than it is thought to be, and NLP researchers unexpectedly agree that we should do more to incorporate insights and methods from domain sciences, and that we should prioritize problem formulation and task design
- ![[2023_NLP_Community_Metasurvey_questions_01.png]]
- ![[2023_NLP_Community_Metasurvey_questions_02.png]]
- ![[2023_NLP_Community_Metasurvey_questions_03.png]]
---
