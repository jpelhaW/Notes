### DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation
---
- [Zotero Select Link](zotero://select/groups/2480461/items/6MP7UMH5)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/6MP7UMH5)
- Authors: [[Yizhe Zhang]] [[Bill Dolan]]
- Topics: [[nlp_chatbot]] [[nlp_qa]] [[nlp_transformers]]
- Venue: #arXiv 
- Year: #2020
---
### Major Contributions
- DIALOGPT, a tunable gigaword scale neural network model for generation of conversational reponses, trained on Reddit data

---
### Secondary Contribution
- DIALOGPT can be easily leveraged and adapted to new dialogue datasets, especially datasets with few training examples.
---
### Limitations/Future Work
---
### Notes (Try to use backlinks)
- Neural response generation is a subcategory of text-generation that shares the objective of generating natural-looking text (distinct from any training instance) that is relevant to the prompt.
- We also excluded a large number of subreddits that had been identified as likely to contain offensive content.
---
