### Unnatural Instructions: Tuning Language Models with (Almost) No Human Labor
---
- [Zotero Select Link](zotero://select/groups/2480461/items/BTYZIXYI)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/BTYZIXYI)
- Authors: [[Or Honovich]] [[Omer Levy]] [[Timo Schick]] 
- Topics: [[nlp_train]] [[nlp_LLM]] [[nlp_data]]
- Venue: #arxiv #ACL #meta 
- Year: #2023

---
### Major Contributions
- Can we create a large dataset of instructions that is diverse in tasks, content, and phrasing, without human labor?
- we introduce Unnatural Instructions: a large dataset of creative and diverse instructions, collected with virtually no human labor. We collect 64,000 examples by prompting a language model with three seed examples of instructions and eliciting a fourth.
	- despite containing a fair amount of noise, training on Unnatural Instructions rivals the effectiveness of training on open-source manually-curated datasets, surpassing the performance of models such as T0++ and Tk-Instruct across various benchmarks
	- Total 240.670 diverse natural language instructions
	- I see more and more the movement of using generated/synthetic data over human labor intensive one
---
### Secondary Contribution
- LMentry LMentry (Efrat et al., 2022) is a benchmark that tests basic language abilities, designed to complement common approaches for evaluating large language models.
- While T5-LM finetuned on Unnatural Instructions is outperformed by FLAN-T5, that model was trained on approximately 60 times more data.
- Important entry for the benefit of paraphrasing: Adding instruction paraphrases boosts performance on T0: Zero-Shot (+3.3), Big-bench: Hard in its original format (+12.1) and LMentry (+8.7).
	- caveat:While some of the performance gains observed may also be attributed to the fact that adding paraphrases simply increases the data,
- “Results for LMentry (Figure 5) show that our template expansion process is still beneficial when controlling for dataset size. The added value of the paraphrases is therefore likely to be in terms of format diversity rather than solely as a method for increasing the amount of data.” (Honovich et al., 2023, p. 14415)
---
### Limitations/Future Work
- Unnatural Instructions contains noisy examples, in which either the instruction, input, or output are invalid.
- future work may employ a human-inthe-loop approach, where humans should recognize challenging patterns, encouraging models to generate more complex examples
- language models are known to sometimes reflect undesirable biases present in their training data. Automatically generated data may therefore contain such content.
---
### Notes (Try to use backlinks)
- we collect data in a fully automatic manner by prompting a pretrained language model with three examples from the [[_2022_Super_Natural_Instructions]] datase (Mishra et al., 2022; Wang et al., 2022) and asking the model to generate a fourth (Figure 1).
	- the entire process requires only 15 instruction examples
- Although the dataset contains noise, our analysis reveals that more than 50% of generated examples are indeed correct, and that even incorrect examples typically contain valuable information for instruction tuning
- We observe a log-linear relationship between the number of generated examples and downstream task performance, suggesting that performance of models trained on Unnatural Instructions can further be improved simply by increasing its size
- **Creativity** A major challenge when creating an instruction dataset is task creativity. Crowd workers typically collapse into predictable heuristics to form annotation artifacts (Gururangan et al., 2018).
- **Correctness** When evaluating correctness, we test whether (1) the generated instructions are logical and executable, (2) the input arguments correspond to the task described in the instruction, and (3) the outputs are correct, given the instruction and input.
- **Diversity** We manually cluster the instructions into tasks and measure the number of unique types. Out of the 200 examples tested, we identify 117 distinct tasks.
- informative and diverse instructions can be generated by untuned language models. However, generating outputs does seem to require instruction tuning.
- ![[2023_Unnatural_Instructions_example.png]]
---
