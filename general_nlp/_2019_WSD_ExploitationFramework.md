### Word Sense Disambiguation: A comprehensive knowledge exploitation framework
---
- [Zotero Select Link](zotero://select/groups/2480461/items/6S4UHBVB)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/6S4UHBVB)
- Authors: [[Yinglin Wang]] [[Ming Wang]]
- Topics: [[topic1]] [[topic2]]
- Venue: #KBS #ELSEVIER (Knowledge-Based Systems)
- Year: #2019
---
### Major Contributions
- In this paper, we focus on the task of all-word [[WSD]] and propose a [[WSD]] framework that exploits background knowledge from three perspectives.
	- First, a unique distributional vector is used to represent each word in the disambiguation process.
	- A naïve IR is used to retrieve domain documents from Wikipedia, to further combine different background information together for LSA to learn the semantics in documents
	- Finally the core competitor of a knowledge-based WSD approach is to utilize knowledge in lexical knowledge bases such as WordNet. 
		- A novel way has been developed in this research to exploit sense relations in WordNet, treating them differently according to their relativity and contribution
	- 
---
### Secondary Contribution
- graph-based approaches achieve better results owing to the utilization of massive sense relations within a semantic network.
- hypernyms are better contributors in the task of WSD from both semantic and statistical viewpoints.
- explanation of using dot product instead of cosine similiarity seems weak - is the magnitude important?
- the discussion about the "best" results is somehow convoluted to hide their system is actually not the best one.
---
### Limitations/Future Work
- The related work has no comparision against the proposed technique
- not much explanation/supported for the parameters in their embeddings - decisions seem quite arbtrary
---
### Notes (Try to use backlinks)
- ![[2019_WSDExploitation_architecture.png]]
- the fact that most knowledge-based systems cannot outperform a simple strategy of picking the most frequent sense indicates that domain knowledge is necessary to bias the word representation vectors learned from a large general corpus to cohere with the documents being disambiguated.
- Synsets of the same POS (noun,verb, adjective and adverb) are connected under some relations separately, although relations might exist when the central idea of two words are the same but in different POS (e.g. adopt and adoption, defined as ‘derivationally related synsets’ in WordNet).
- contribution can be represented as the ratio of overlap between the context and the word collection retrieved by either relation, to the context of the word under disambiguation
- eXtended WordNet (XWN) is exploited to change all the words in definitions and examples into disambiguated senses. eXtended WordNet is a morphologically and semantically enhanced version of WordNet. 
	- It has disambiguated all the words in the definition and examples of the synsets.
- All these datasets but Semeval-13 (only disambiguates nouns) are different from the official datasets since they do not require systems to disambiguate auxiliary verbs
---
