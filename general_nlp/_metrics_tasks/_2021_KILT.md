### KILT: a Benchmark for Knowledge Intensive Language Tasks
---
- [Zotero Select Link](zotero://select/groups/2480461/items/5CFWG8WY)
- [Zotero URI](https://www.zotero.org/groups/2480461/items/5CFWG8WY)
- Authors: [[Fabio Petroni]] [[Sebastian Riedel]] 
- Topics: [[nlp_benchmark]] [[nlp_train]]
- Venue: #NAACL 
- Year: #2021
---
### Major Contributions
 - [KILT](https://github.com/ facebookresearch/KILT.1)
	 - we introduce KILT, a benchmark and library for Knowledge Intensive Language Tasks. KILT aims to lower the entry barrier for such research by formulating several knowledge-intensive NLP tasks with respect to a common interface and the same unified knowledge source—a single Wikipedia snapshot.
- We evaluate several state-of-the-art models that represent diverse approaches to knowledgeintensive NLP, and find that a hybrid approach combining a neural retriever with a pretrained sequenceto-sequence model outperforms most task-specific solutions when trained end-to-end
- a publicly-available benchmark of knowledgeintensive tasks aligned to a single Wikipedia snapshot, to spur the development of generalpurpose models and enable their comparison;
- an open-source library to facilitate the development of new architectures for knowledgeintensive tasks; 
- a provenance indication for all instances in KILT, made more comprehensive with an annotation campaign, which allows to jointly assess output accuracy and ability to provide supporting evidence in the knowledge source; 
- a comparative performance of various modeling approaches, showing promising results for general baselines across all tasks.
---
### Secondary Contribution
---
### Limitations/Future Work
---
### Notes (Try to use backlinks)
- solving knowledge-intensive tasks requires–even for humans–access to a large body of information. Like in Information Retrieval (IR) this involves satisfying an information need leveraging large collections of text
- we introduce KILT, a benchmark and library for Knowledge Intensive Language Tasks. KILT aims to lower the entry barrier for such research by formulating several knowledge-intensive NLP tasks with respect to a common interface and the same unified knowledge source—a single Wikipedia snapshot.
- there are no unanswerable instances in KILT.
- 
- [[_2021_KILT]]
	- KILT knowledge source is based on the 2019/08/01 Wikipedia snapshot and contains 5.9M articles.
- These provenance spans range from single entities, short answers, sentences, paragraphs, to whole articles. The idea of our mapping strategy is to identify provenance spans in the KILT knowledge source—if we find all the provenance spans for an input-output pair, the knowledge needed to produce the output is available in our snapshot. The provenance can be a span of any size, from a single token to a paragraph to an entire document.
- We consider five tasks that use Wikipedia as a knowledge source for KILT: fact checking, open domain question answering, slot filling, entity linking, and dialogue.
- These test sets are not publicly released, but are used for the KILT challenge on EvalAI (Yadav et al., 2019) where participants can upload their models’ predictions and be listed on the public leaderboard [link](https://evalai.cloudcv.org/ web/challenges/challenge-page/689)
- It’s possible to get the performance of a system for the KILT test sets by uploading its predictions to our EvalAI challenge - **Ask authors for the test set?**
- There are custom solutions that can easily simplify the slot filling task. For instance, subject entities can be used for lookups by title in Wikipedia to retrieve knowledge (this heuristic will always work for zsRE), and structured human-curated resources (such as Wikidata13) could be used to get all answers right. Nevertheless, we are interested in testing if a general model can extract attributes about specific entities from a large body of text
- ![[2021_KILT_interface.png]]
- ![[2021_KILT_Datasets.png]]
---
